# ğŸ“„ RAG AI Assistant â€“ Document Chat System

A **Retrieval-Augmented Generation (RAG)** based AI assistant that allows users to upload documents and chat with them through a ChatGPT-like interface.

This project combines **FastAPI**, **LangChain**, **ChromaDB**, and **Groq LLMs** to deliver accurate, document-grounded answers with persistent chat history per document.



## ğŸš€ Features

### âœ… Core Capabilities

* ğŸ“‚ Upload documents (PDF, TXT, DOCX, etc.)
* ğŸ§  Automatic text extraction, chunking, and embedding
* ğŸ” Semantic retrieval using vector similarity (RAG)
* ğŸ’¬ Chat with **one selected document at a time**
* ğŸ—‚ï¸ Separate chat history per document
* â™»ï¸ Persistent storage (files, vectors, history survive restarts)

### âœ… User Experience

* professional-style interface
* Sidebar document list
* Instant document switching
* Auto-load previous chat history
* Clean scrolling chat UI
* Upload validation & error handling


## ğŸ–¼ï¸ User Interface
### Initial ui
![Initial UI](screenshots/initial.png)


### ğŸ“‚ Document Selection & Upload
![Upload UI](screenshots/upload.png)

### ğŸ’¬ Chat with Document
![Chat UI](screenshots/chat.png)

### ğŸ“‘ Sidebar Navigation
![Sidebar](screenshots/sidebarcollapse.png)




---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Frontend  â”‚  (HTML + CSS + JS)
â”‚  Chat UI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI     â”‚
â”‚  API Layer    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€ File Upload
        â”‚     â””â”€ Text Extraction
        â”‚     â””â”€ Chunking
        â”‚     â””â”€ Embeddings
        â”‚     â””â”€ Vector Storage
        â”‚
        â”œâ”€â”€ Chat Requests
        â”‚     â””â”€ Retriever (ChromaDB)
        â”‚     â””â”€ Context Builder
        â”‚     â””â”€ LLM (Groq)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChromaDB     â”‚
â”‚  Vector Store â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```



## ğŸ§  RAG Pipeline

1. **Upload Document**
2. **Text Extraction**
3. **Chunking**
4. **Embedding (HuggingFace)**
5. **Vector Storage (ChromaDB)**
6. **Query Embedding**
7. **Semantic Retrieval**
8. **Context Injection**
9. **LLM Answer Generation**

The LLM is strictly instructed to answer **only from retrieved context**.



## ğŸ› ï¸ Tech Stack

### Backend

* **FastAPI**
* **LangChain**
* **ChromaDB**
* **Groq LLM**
* **Pydantic**

### AI / ML

* `sentence-transformers/all-MiniLM-L6-v2`
* Retrieval-Augmented Generation (RAG)

### Frontend

* HTML
* CSS
* Vanilla JavaScript



## ğŸ“ Project Structure

```
rag-ai-assistant/
â”‚
â”œâ”€â”€ app.py                 # FastAPI application
â”œâ”€â”€ vectordb.py            # Ingestion, chunking, embeddings, storage
â”œâ”€â”€ retriever.py           # Semantic search logic
â”œâ”€â”€ llm_engine.py          # RAG prompt + LLM invocation
â”œâ”€â”€ text_extractor.py      # File text extraction
â”‚
â”œâ”€â”€ uploads/               # Uploaded documents
â”œâ”€â”€ history/               # Per-documentallon chat history
â”œâ”€â”€ chromadb_db/           # Vector database
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # UI
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css          # UI styling
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```



## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/rag-ai-assistant.git
cd rag-ai-assistant
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Environment Variables

Create a `.env` file:

```env
GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=llama-3.1-8b-instant
```

---

## â–¶ï¸ Run the Application

```bash
uvicorn app:app --reload
```

Open in browser:

```
http://127.0.0.1:8000
```



## ğŸ’¬ How to Use

1. Upload a document using the **+ Upload** button
2. Select the document from the sidebar
3. Ask questions related to that document
4. Switch documents to start a new contextual chat
5. Chat history is automatically preserved per document



## ğŸ” Design Decisions

* **Single-file context** (no multi-file mixing)
  â†’ Improves answer accuracy and UX clarity

* **File-scoped chat history**
  â†’ Prevents cross-document contamination

* **No session IDs**
  â†’ Simple, filename-based persistence (ideal for local apps)

* **Strict RAG prompt**
  â†’ Prevents hallucinations



## âš ï¸ Known Limitations

* Only **one document at a time**
* No streaming responses (yet)
* No authentication
* No document deletion UI
* Designed for local / demo use (not production-scale)



## ğŸ”® Future Improvements

* ğŸ”„ Streaming (token-by-token) responses
* ğŸ“‘ Source citations per answer
* ğŸ§  Improved multi-file reasoning
* ğŸ§¾ Markdown rendering
* ğŸ—‘ï¸ Document deletion
* ğŸŒ React frontend
* ğŸ” User authentication


## ğŸ“Œ Status

**âœ” Functional
âœ” Stable
âœ” Clean UX
âœ” Resume-ready project**



## ğŸ‘¨â€ğŸ’» Author

**Dawal Malik**
AI / ML Developer
Focused on RAG systems, LLMs, and applied AI engineering

